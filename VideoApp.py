import streamlit as st
import cv2
import os
from PIL import Image
import captionGenerate
import requests
import io
from io import BytesIO
from PIL import ImageDraw
from PIL import ImageFont
from st_pages import Page, Section, show_pages, add_page_title, hide_pages
import mysql.connector
from mysql.connector import Error
import time
import hashlib

#ç™¾åº¦ç¿»è¯‘APIè°ƒç”¨
def translate_with_baidu(text, source_language='en', target_language='zh'):
    # è¿™é‡Œå¡«å…¥ç™¾åº¦ç¿»è¯‘APIåº”ç”¨ä¿¡æ¯
    app_id = '20240406002016043'
    app_key = 'b2UhlL_ZcDSSClFhWlcC'

    url = 'https://fanyi-api.baidu.com/api/trans/vip/translate'
    payload = {
        'q': text,
        'from': source_language,
        'to': target_language,
        'appid': app_id,
        'salt': 'random_salt',  # éšæœºæ•°
        'sign': '',  # ç­¾å
    }
    sign_str = app_id + text + 'random_salt' + app_key
    payload['sign'] = hashlib.md5(sign_str.encode()).hexdigest()

    response = requests.post(url, data=payload)
    translation = response.json()
    if 'error_code' in translation:
        print("Translation Error:", translation['error_code'])
        return None
    elif 'trans_result' in translation:
        return translation['trans_result'][0]['dst']
    else:
        return None

def videoProcess(path):
    '''è¯»å–mp4æ–‡ä»¶å¹¶è¿›è¡Œåˆ†å‰²'''
    cam = cv2.VideoCapture(path)
    try:
        # åˆ›å»ºåä¸ºdataçš„æ–‡ä»¶å¤¹
        if not os.path.exists('Frames'):
            os.makedirs('Frames')
            print('æˆåŠŸåˆ›å»ºåˆ‡å¸§æ–‡ä»¶å¤¹')

    # å¦‚æœæœªåˆ›å»ºï¼Œåˆ™å¼•å‘é”™è¯¯
    except OSError:
        print('Error: åˆ›å»ºåˆ‡å¸§æ–‡ä»¶å¤¹æ—¶é”™è¯¯ï¼')

    # å®šä¹‰ä¿å­˜å›¾ç‰‡å‡½æ•°
    # image:è¦ä¿å­˜çš„å›¾ç‰‡åå­—
    # addrï¼›å›¾ç‰‡åœ°å€ä¸ç›¸ç‰‡åå­—çš„å‰éƒ¨åˆ†
    # num: ç›¸ç‰‡ï¼Œåå­—çš„åç¼€ã€‚int ç±»å‹
    def save_image(image, addr, num):
        address = addr + str(num) + '.jpg'
        cv2.imwrite(address, image)

    # è·å–è§†é¢‘çš„æ€»å¸§æ•°
    total_frames = int(cam.get(cv2.CAP_PROP_FRAME_COUNT))

    frames_to_capture = 6  # è¦æˆªå–çš„å¸§æ•°
    interval = total_frames // frames_to_capture  # è®¡ç®—æˆªå–å¸§çš„é—´éš”

    i = 0
    frame_index = 0
    while i < frames_to_capture:
        # è®¾ç½®è§†é¢‘çš„å¸§ç´¢å¼•
        cam.set(cv2.CAP_PROP_POS_FRAMES, frame_index)
        ret, frame = cam.read()
        if not ret:
            break  # å¦‚æœæ— æ³•è¯»å–å¸§ï¼Œåœæ­¢å¾ªç¯
        save_image(frame, './Frames/', i + 1)
        i += 1
        # æ›´æ–°ä¸‹ä¸€ä¸ªè¦è¯»å–çš„å¸§çš„ç´¢å¼•
        frame_index += interval

    cam.release()
    cv2.destroyAllWindows()

# å®šä¹‰åµŒå…¥å›¾ç‰‡å­—å¹•çš„å‡½æ•°
def generate_captioned_image(image, caption, font_size, font_color, chosen_position):
    draw = ImageDraw.Draw(image)  # åˆ›å»ºå›¾åƒç»˜åˆ¶å¯¹è±¡
    chosen_font_path = "simhei.ttf"
    font = ImageFont.truetype(chosen_font_path, font_size)

    # è®¾ç½®å­—ä½“æ ·å¼ï¼Œå°†åå…­è¿›åˆ¶é¢œè‰²å€¼è½¬æ¢ä¸º RGB å…ƒç»„
    font_color = tuple(int(font_color.lstrip('#')[i:i + 2], 16) for i in (0, 2, 4))

    # åœ¨å›¾ç‰‡ä¸‹æ–¹æ·»åŠ å­—å¹•
    text_width, text_height = draw.textsize(caption, font=font)  # è·å–å­—å¹•æ–‡æœ¬çš„å®½åº¦å’Œé«˜åº¦
    image_width, image_height = image.size  # è·å–å›¾ç‰‡çš„å®½åº¦å’Œé«˜åº¦

    # è®¡ç®—å­—å¹•æ–‡æœ¬çš„ä½ç½®ï¼Œä½¿å…¶ä½äºå›¾ç‰‡ä¸­å¿ƒçš„ä¸‹æ–¹
    text_position = ((image_width - text_width) // 2, image_height - text_height - chosen_position)

    # ç»˜åˆ¶å­—å¹•æ–‡æœ¬
    draw.text(text_position, caption, font=font, fill=font_color)

def video_predict():
    # åˆå§‹åŒ– CaptionGenerator å®ä¾‹
    checkpoint_paths = []  # æ¨¡å‹çš„checkpointè·¯å¾„åˆ—è¡¨
    checkpoint_paths.append('checkpointA.pth')

    # åˆå§‹åŒ–æ•°æ®
    caption_generator = captionGenerate.CaptionGenerator(checkpoint_paths)
    # ç”¨äºå­˜æ”¾å›¾ç‰‡æ¦‚è¿°çš„åˆ—è¡¨
    generate_captions = []
    #ç”¨äºå­˜æ”¾åŸåˆ‡ç‰‡çš„åˆ—è¡¨
    images_origin = []
    # ç”¨äºå­˜æ”¾å¤„ç†åå›¾ç‰‡çš„åˆ—è¡¨
    images_to_show = []


    for filename in os.listdir("Frames"):
        # æ‹¼æ¥æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        file_path = os.path.join("Frames", filename)

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºå›¾ç‰‡æ–‡ä»¶
        if os.path.isfile(file_path) and filename.lower().endswith((".jpg", ".jpeg", ".png")):
            # è¯»å–å›¾åƒ
            image_path = file_path
            image = Image.open(image_path)
            # å°†ä¸Šä¼ çš„åŸå§‹å›¾ç‰‡å­˜åˆ°sessionä¸­
            images_origin.append(image)
            st.session_state.images_origin = images_origin[:]

            result = caption_generator.generate_caption(image)

            for caption_item in result:
                # ä½¿ç”¨ç¿»è¯‘apiå°†ç”Ÿæˆçš„å­—å¹•ç¿»è¯‘ä¸ºä¸­æ–‡
                translated_result = translate_with_baidu(caption_item, source_language='en', target_language='zh')
                generate_captions.append(translated_result)
                # å°†ç”Ÿæˆçš„å­—å¹•å­˜åˆ°sessionä¸­
                st.session_state.generate_captions = generate_captions[:]

                #è®¾ç½®å­—ä½“å‚æ•°
                font_size = 50
                font_color = "#000000"
                temp_image = image.copy()
                chosen_position = 70
                generate_captioned_image(temp_image, translated_result, font_size, font_color, chosen_position)
                # å°†å¤„ç†åçš„å›¾ç‰‡æ·»åŠ åˆ°å¾…å±•ç¤ºçš„å›¾ç‰‡åˆ—è¡¨ä¸­
                images_to_show.append(temp_image)
                if len(images_to_show) == 6:
                    st.image(images_to_show, width=350)
                    images_to_show = []


# Streamlit åº”ç”¨ç¨‹åº
def main():
    st.title("è§†é¢‘æ•…äº‹æ¦‚æ‹¬")
    st.markdown("---")

    # æ£€æŸ¥ caption_generated å˜é‡æ˜¯å¦åœ¨ä¼šè¯çŠ¶æ€ä¸­ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è®¾ç½®ä¸º False
    if 'VideoCaption_generated' not in st.session_state:
        st.session_state.VideoCaption_generated = False

    #ç”¨äºå­˜æ”¾å›¾ç‰‡æ¦‚è¿°åˆ‡ç‰‡çš„åˆ—è¡¨
    images_origin = []

    # é»˜è®¤å­—ä½“åˆ—è¡¨
    default_fonts = {"é»‘ä½“": "simhei.ttf", "å¾®è½¯é›…é»‘": "msyhbd.ttc", "æ¥·ä½“": "simkai.ttf", "æ–°å®‹ä½“": "simsun.ttc"}

    vid_upload = st.file_uploader("ğŸ“¤ ä¸Šä¼ è§†é¢‘æ–‡ä»¶ (.mp4)", type=["mp4"])


    if vid_upload != None and not st.session_state.VideoCaption_generated:

        # è°ƒç”¨ç”Ÿæˆå­—å¹•çš„å‡½æ•°å¹¶è·å–ç»“æœ
        with st.spinner(text="ğŸ–Œï¸ æ­£åœ¨åŠ è½½è§†é¢‘ï¼Œè¯·ç¨ç­‰..."):
            video_bytes = vid_upload.read()
            # æ’­æ”¾è§†é¢‘
            with open("temp_video.mp4", "wb") as f:
                f.write(video_bytes)
            # è·å–è§†é¢‘æ–‡ä»¶çš„æœ¬åœ°è·¯å¾„
            video_path = "temp_video.mp4"
            st.video(video_bytes)
            # è°ƒç”¨å…¶ä»–å‡½æ•°ï¼Œå¹¶å°†è§†é¢‘è·¯å¾„ä½œä¸ºå‚æ•°ä¼ é€’
        with st.spinner(text="ğŸ–Œï¸ æ­£åœ¨å°†è§†é¢‘åˆ‡ç‰‡ï¼Œè¯·ç¨ç­‰..."):
            videoProcess(video_path)
        with st.spinner(text="ğŸ–Œï¸ æ­£åœ¨ä¸ºåˆ‡ç‰‡ç”Ÿæˆæ¦‚è¿°ï¼Œè¯·ç¨ç­‰..."):
            video_predict()
            # è®¾ç½®æ ‡å¿—å˜é‡ä¸º Trueï¼Œè¡¨ç¤ºå·²ç”Ÿæˆå­—å¹•,é˜²æ­¢é¡µé¢é‡åŠ è½½ä¸€ç›´ç”Ÿæˆï¼ŒåŒæ—¶æ˜¾ç¤ºå­—å¹•ç¼–è¾‘é€‰å•
            st.session_state.VideoCaption_generated = True
            # åˆ é™¤åˆ‡å¸§çš„ä¸´æ—¶æ–‡ä»¶å¤¹è·¯å¾„
            folder_path = 'Frames'
            try:
                # æ¸…ç©ºæ–‡ä»¶å¤¹å†…çš„å†…å®¹
                files = os.listdir(folder_path)
                for file in files:
                    file_path = os.path.join(folder_path, file)
                    os.remove(file_path)
                 # åˆ é™¤æ–‡ä»¶å¤¹åŠå…¶å†…å®¹
                os.rmdir(folder_path)
                print("åˆ‡å¸§æ–‡ä»¶å¤¹åˆ é™¤æˆåŠŸ")
            except OSError as e:
                print(f"åˆ‡å¸§åˆ é™¤æ–‡ä»¶å¤¹å¤±è´¥: {e}")

    #ç”¨æˆ·è‡ªå®šä¹‰æ–‡å­—æ ·å¼æ¨¡å—
    if st.session_state.VideoCaption_generated:
        # å­—ä½“æ ·å¼é€‰é¡¹
        chosen_font = st.selectbox("ğŸ—› é€‰æ‹©å­—ä½“:", options=default_fonts)
        chosen_font_path = default_fonts[chosen_font]
        font_size = st.slider("ğŸ—š é€‰æ‹©å­—ä½“å¤§å°:", min_value=10, max_value=100, step=2, value=25)
        chosen_position = st.slider("ğŸ“ è°ƒæ•´æ–‡å­—ä½ç½®:", min_value=10, max_value=500, step=5, value=50)
        font_color = st.color_picker("ğŸ¨ é€‰æ‹©å­—ä½“é¢œè‰²:", "#000000")
        chosen_captions = st.session_state.generate_captions
        images_to_show = []
        if st.button("ä¿®æ”¹æ–‡å­—æ ·å¼"):
            st.empty()  # æ¸…ç©ºè¾“å‡º
            for index, images in enumerate(st.session_state.images_origin):
                if index < len(chosen_captions):
                    chosen_caption = chosen_captions[index]
                else:
                    chosen_caption = "å­—å¹•å‡ºé”™ï¼Œè¯·è”ç³»å¼€å‘è€…"  # é˜²æ­¢è¯»å–é”™è¯¯ç¨‹åºç»ˆæ­¢çš„æƒ…å†µ
                temp_image = images.copy()
                generate_captioned_image(temp_image, chosen_caption, font_size, font_color, chosen_position)
                images_to_show.append(temp_image)
                if len(images_to_show) == 6:
                    st.image(images_to_show, width=350)
                    images_to_show = []

if __name__ == "__main__":
    main()